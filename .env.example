# LiteLLM Configuration
# The following settings are now hardcoded:
# - Model alias: gpt-5
# - Master key: LITELLM_MASTER_KEY environment variable (default: sk-local-master)
# - Host: 0.0.0.0
# - Port: PORT environment variable (default: 4000)
# - Workers: 1
# - Debug: false
# - Detailed debug: false
# - Drop params: true

# Port Configuration
PORT=4000

# Master Key Configuration
LITELLM_MASTER_KEY=sk-local-master

# Streaming Configuration
IS_STREAMING=true

# Reasoning Configuration (for supported models like AgentRouter GPT-5)
# Valid values: none, low, medium, high
# Default: medium
REASONING_EFFORT=medium

# OpenAI API Configuration
OPENAI_MODEL=gpt-5
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=sk-your-openai-api-key-here

# Test-specific settings
TEST_TIMEOUT=30
TEST_MAX_TOKENS=500

