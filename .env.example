# LiteLLM Configuration
# The following settings are now hardcoded:
# - Host: 0.0.0.0
# - Port: PORT environment variable (default: 4000)
# - Workers: 1
# - Debug: false
# - Detailed debug: false

# Port Configuration
PORT=4000

# Master Key Configuration
LITELLM_MASTER_KEY=sk-local-master

# Streaming Configuration
IS_STREAMING=true

# Global defaults (used when individual model entries omit values)
OPENAI_BASE_URL=https://agentrouter.org/v1
OPENAI_API_KEY=sk-your-upstream-api-key  # secret read by LiteLLM and referenced by generated config

# Token Limits / other shared knobs
MAX_TOKENS=8192

# ---------------------------------------------------------------------------
# Multi-model Proxy Configuration
# ---------------------------------------------------------------------------
# Define logical keys for each model. Keys must be alphanumeric/underscore.
# This allows running multiple models concurrently from a single proxy instance.

# Example 1: Multi-model setup (GPT-5 + DeepSeek v3.2 + Grok + GLM-4.6)
# Uncomment lines below to enable all models
# PROXY_MODEL_KEYS=gpt5,deepseek,grok,glm

# GPT-5 model configuration (supports reasoning effort)
# MODEL_GPT5_UPSTREAM_MODEL=gpt-5
# MODEL_GPT5_REASONING_EFFORT=medium

# DeepSeek v3.2 model configuration (supports reasoning effort)
# MODEL_DEEPSEEK_UPSTREAM_MODEL=deepseek-v3.2
# MODEL_DEEPSEEK_REASONING_EFFORT=medium

# Grok Code Fast-1 model configuration (supports reasoning effort)
# MODEL_GROK_UPSTREAM_MODEL=grok-code-fast-1
# MODEL_GROK_REASONING_EFFORT=high

# GLM-4.6 model configuration (does NOT support reasoning effort)
# MODEL_GLM_UPSTREAM_MODEL=glm-4.6
# Note: GLM_API_KEY should be set separately if using GLM from a different provider

# Example 2: Single-model setup using new schema (alias auto-derived)
# PROXY_MODEL_KEYS=primary
# MODEL_PRIMARY_UPSTREAM_MODEL=gpt-5
# MODEL_PRIMARY_REASONING_EFFORT=medium

# Example 3: Single DeepSeek model (alias auto-derived)
# PROXY_MODEL_KEYS=deepseek
# MODEL_DEEPSEEK_UPSTREAM_MODEL=deepseek-v3.2
# MODEL_DEEPSEEK_REASONING_EFFORT=medium

# Test-specific settings
TEST_TIMEOUT=30
TEST_MAX_TOKENS=500